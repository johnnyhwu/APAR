cd ../..

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_5\ \(v6bhkkpy\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v6bhkkpy \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 1.0

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_1\ \(emviixrp\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id emviixrp \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 1.0

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_multiply_0_01\ \(p61qixsh\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id p61qixsh \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 1.0

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_arithmetic_mean\ \(5zwqq590\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id 5zwqq590 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_arithmetic_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 1.0

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.1

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.3

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.5

python semi_finetune.py \
--exp_name bs-APAR-semi_finetune_geometric_mean\ \(ejd6n625\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset bs \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id ejd6n625 \
--pretrain_wandb_name ckpt/self_pretrain/bs-APAR-self_pretrain_geometric_mean.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 1.0