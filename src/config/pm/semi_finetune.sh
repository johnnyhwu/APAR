cd ../..

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_add\ \(daot5uuc\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id daot5uuc \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_add.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_subtract\ \(lnh2bf9q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id lnh2bf9q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_subtract.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_1\ \(dm0hg1uk\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id dm0hg1uk \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_5\ \(zmznrt9l\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id zmznrt9l \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_5.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_1\ \(iki2s9tg\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id iki2s9tg \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_1.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_multiply_0_01\ \(r0f9hv1q\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id r0f9hv1q \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_multiply_0_01.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.01 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.1 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.2 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.3 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.4 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.5 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.6 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.7 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.8 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 0.9 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.003 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01

python semi_finetune.py \
--exp_name pm-APAR-semi_finetune_division\ \(v3hwxpwj\) \
--batch_size 256 \
--val_ratio 0.1 \
--val_freq 100 \
--learning_rate 0.0005 \
--total_epoch 100 \
--device 0 \
--seed 47 \
--dataset pm \
--numerical_feature_encoding log2_delta \
--categorical_feature_encoding label \
--target_encoding log2_delta \
--pretrain_wandb_id v3hwxpwj \
--pretrain_wandb_name ckpt/self_pretrain/pm-APAR-self_pretrain_division.pt \
--pred_loss_weight 1.0 \
--csty_loss_weight 1.0 \
--ftpy_loss_weight 0.01